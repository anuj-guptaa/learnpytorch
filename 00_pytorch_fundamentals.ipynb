{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a7991b-ce55-433d-b8f4-ef1595168d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = \"http://192.41.170.23:3128\" \n",
    "os.environ['https_proxy'] = \"http://192.41.170.23:3128\" \n",
    "\n",
    "# export http_proxy=http://192.41.170.23:3128\n",
    "# export https_proxy=http://192.41.170.23:3128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c2298bb-be42-46c1-803e-9722629bd917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ec8347-89e1-48ec-a64e-e4f56a6493ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is cuda available?\", torch.cuda.is_available())\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3611fe3-c6e7-408f-a86a-99cda4265f4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 00. PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50c3f90c-effe-46ec-ba0d-de9ea3514ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713fc6d-fef0-4905-ae2c-042a683767dd",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "Pytorch tensors are craeted using torch.Tensor() = https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2430b0a-97f4-4c83-883b-09a628804a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdee578a-2111-4c09-b8e6-56f6ce45defa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a729ee76-0672-478d-9671-944ae5f1383e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ad5a5fd-44c7-4175-ada5-47ae1b6cde08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4553b834-17de-4bff-adab-4e3dfc53a8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7ccb935-0d54-4dbb-8145-c93095135e26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16f19c8d-d4a5-46e3-b31c-43181ff6ce5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc8d7fb5-fc0b-4cec-a5f4-5766bd9fe6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17d99a02-ce56-4fc9-bd6c-ce813aff3b28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89f4cee3-07a7-42c1-b190-ffd90f405625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0eb4664b-ff84-452a-bf60-4f032e3b8d90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 6],\n",
       "         [2, 4],\n",
       "         [5, 1],\n",
       "         [3, 4]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2],\n",
    "                        [3,6],\n",
    "                        [2,4],\n",
    "                        [5,1],\n",
    "                        [3,4]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89de1a23-8eb9-4b08-9290-e113ee404184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93e629fb-97cc-4781-8529-0dd308ef2494",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60bfcdb9-b484-401c-ba1c-4d395fa2f39b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 6],\n",
       "        [2, 4],\n",
       "        [5, 1],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff77d7f-3f62-4bd5-9aac-d1e99f15b19b",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important because the way many nerual networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> update random numbers`\n",
    "\n",
    "Torch random tensors - https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4187bb6d-0f01-43ab-a5a2-d64aac7a3a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1162, 0.2684, 0.2864, 0.5678],\n",
       "        [0.1267, 0.1307, 0.0152, 0.7556],\n",
       "        [0.3047, 0.5696, 0.1587, 0.2690]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a81fccae-3f59-4a05-8fa3-65dc1ba1b5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channels (R, G, B)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5361ef-bb03-4663-8cbd-e21e9c8b42fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e141876-3742-4a23-b26c-6e8eefdb9aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "195c88eb-a070-450e-bc15-334ec249acca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a12e96dc-0f89-4f5f-a606-ed17978b9878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a81201e-a545-468b-ad30-031abc65594e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e096fb-b1d1-4f12-b773-98da09190eb7",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2f3544ff-881b-4aa7-afd0-426ff6582551",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range()\n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d34a7b9-bd7a-4642-a87f-efe7e2d7808e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46744e0-5b30-41f6-82e0-ff1c7aa1e74d",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch and deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5902b5f5-86cd-4668-878f-757681338922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                                dtype=None, # what datatype is the tensor (e.g. float32, float16)\n",
    "                                device=None, # What device is your tensor on \n",
    "                                requires_grad=False) # whether or not to track gradients with this tensor's operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8416238b-2d07-4672-9224-79431abab146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2ed50b9-a0d5-4db9-a0dc-9de40e586644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ebd687d3-c4f4-4c30-8135-6b1af3681810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3580bee-6eff-4ffd-acc1-9d10266c74de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0ff8875-c90f-4ce5-a434-d7ddef4c2d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "605c27d1-2f01-44ac-8114-99d80b5ca49a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b22b98-53ff-4475-9a9c-2a518a2df2cf",
   "metadata": {},
   "source": [
    "### Getting information from tensors (tensor attributes)\n",
    "\n",
    "1. Tensors not right datatype - to get datatype from tensor, use `tensor.dtype`\n",
    "2. Tensors not right shape - to get shape from a tensor, use `tensor.shape`\n",
    "3. Tensors not on right device - to get device from a tensor, use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1cce2f73-a8d8-4adb-aa52-3492e9ca4762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4634, 0.0440, 0.8924, 0.8980],\n",
       "        [0.2296, 0.9528, 0.8127, 0.0446],\n",
       "        [0.2259, 0.1004, 0.2010, 0.1034]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1b377602-3d38-483c-bc9f-afbec067c700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4634, 0.0440, 0.8924, 0.8980],\n",
      "        [0.2296, 0.9528, 0.8127, 0.0446],\n",
      "        [0.2259, 0.1004, 0.2010, 0.1034]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714362ec-9e63-4143-a1ef-b3b7bfd4f094",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b05f2117-2409-47b5-913c-e53b521f8cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0fc6a88d-6376-4a87-839c-d40eb23b9c21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2da84b2f-0b19-45d2-9ae1-41ea6e2c919f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract tensor by 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "97d120e5-1b5a-4df3-a854-06c6703311ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 20, 30])\n",
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "# Try out PyTorch in-built functions\n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.add(tensor, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "057a7fab-a874-4432-979e-3df58d1682d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aabd6e-568f-49e6-8131-9e5cbda87e51",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "  \n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "More information on multiplying matrices - https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "\n",
    "There are two rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3, 2) @ (3, 2)` won't work\n",
    "* `(2, 3) @ (3, 2)` will work\n",
    "* `(3, 2) @ (2, 3)` will work\n",
    "2. The resulting matrix has the shape of the **outer dimensions**:\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "* `(3, 2) @ (2,3 )` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8328564e-dc3d-47f0-888a-02def0a86518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(10, 10), torch.rand(10, 10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db3c69aa-f47c-4f08-ab8b-fb340a3b0e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, '*', tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "21689673-5d58-4d4b-936c-7a11fedc30e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e65321dd-995f-4940-bab0-949d01d064c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6a5780c8-d8de-4385-bf86-9cad762ffc13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4b1f52aa-22a4-47c5-b4bc-1768a87aeb78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: user 377 µs, sys: 167 µs, total: 544 µs\n",
      "Wall time: 723 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0 \n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "  \n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "892b3633-db5b-4945-b4da-b867167715b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 µs, sys: 0 ns, total: 37 µs\n",
      "Wall time: 37.4 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc5881-e95e-4b9f-b789-121a0c9785e1",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8ae13c7f-b8fa-486b-bbb1-661604590984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      6\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# torch.mm = torch.matmul = @\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "\n",
    "torch.mm(tensor_A, tensor_B) # torch.mm = torch.matmul = @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "807ebae0-40fc-4ec1-ae4d-ccc6c4232f29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba21da-e9c4-44a9-a458-253978dc8f1b",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fca1cfb3-095b-4fde-90d8-110da3e0c721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "96c31210-8d59-4520-8dec-6a3972c41483",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7d3e3f98-dbc4-40ca-9aeb-0d728f31a884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3])\n",
      "Output:\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The matrix multiplication operation works when tensor_B is transposed\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape}, tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape}\")\n",
    "print(\"Output:\")\n",
    "output = torch.mm(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb83e26-ff89-4f48-98bd-10518ff06c4d",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "22160570-876b-4303-8179-00d70b9e8ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "221fb174-9890-448b-ab24-c2a81ac3bdd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5b2ea452-d0c6-4916-a8f9-8d5eff70e14f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(91), tensor(91))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3200fcfa-ef19-45f4-b196-21b106975525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(46.), tensor(46.))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - note the torch.mean() function requires a tensor of float32 datatype to work\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a7808100-1c48-4f9d-ba38-29573232ce4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(460), tensor(460))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce09ddb-fce2-4261-a2d1-ea1f9f309e40",
   "metadata": {},
   "source": [
    "## Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2ae9ab35-1af1-43c3-8249-17bada243fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9301c8f8-1bc4-4c30-916d-c35fb010ffd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmin() -> returns index position of target tensor where minimum value occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "759f8f87-bdcf-457d-b439-88efa27fa9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f577e-e728-45f8-b7b9-9ad6451627c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reshaping, stacking, squeezing, and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - adds a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimension permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "803dc090-1712-48d8-a103-2e989c503678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1875a395-7299-499c-93a0-0deecce8f8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6da8ddd4-c08f-4c54-8978-dc0a3525970a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b6385cfe-505c-4e9e-965b-8da757891b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "979b9c0b-0674-40bc-b49d-755ab7f2c2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9114018b-884e-4ad7-86c3-b1bb27eeb4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New tensor shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() = removes all single dimensions from a target tensors\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New tensor shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ac2de5c6-c4ff-4142-8d57-4f5d6b3983fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New target: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New target shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target tensor at a specific dim \n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew target: {x_unsqueezed}\")\n",
    "print(f\"New target shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c446af13-66b6-4383-ab65-80bf64675ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color channels]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\") # [color channels, height, width]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3947477-b4a3-42b7-b447-6f2eb2e63111",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors) \n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "42fd3f8b-fc24-4c1c-9e78-f38d777348fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0b78efc8-0d93-4aed-8775-4e9da5a5b7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ee28c10c-2aeb-4163-a239-98cd40c22bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the middle bracket (dim=1)\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2696256e-bbd4-484b-91ae-a69820d4aa7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket (last dimension)\n",
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7b067388-8b09-4537-a0fb-40fbbffbf981",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use ':' to select \"all\" of a target dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2877faa9-0e75-4eea-ad97-5bc7fb9f5937",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0th and 1st deimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "18a17c05-55c4-42a5-bc22-69885802f0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimensions\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fbc6bad0-331e-4b42-9780-f676c7a8e4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7109ee87-b497-4766-ae9a-cc25b7360a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "print(x[0,2,2])\n",
    "\n",
    "# Index of x to return 3, 6, 9 \n",
    "x[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b75660-23c1-4301-8918-82e8aeaae21d",
   "metadata": {},
   "source": [
    "# PyTorch tensors and NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library. \n",
    "\n",
    "PyTorch has functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0f0e5580-780b-47f9-b894-e8918ef1107a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # when converting from numpy -> pytorch reflects numpy's default dtype of float64\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "53875e70-5a26-4016-a59b-50348cc4e76f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "730d85b2-0dc5-4596-8f17-373ed37b2792",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e60288ec-2686-4b2d-8f01-0ceca4e11649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to `numpy` tensor?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06142d99-41f0-40fb-926b-a03e8caa908d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reproducibility (trying to take random out of random)\n",
    "\n",
    "In short, how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
    "\n",
    "Essentially what the random seed does is \"flavor\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "20851687-87ed-41aa-87cd-87fb1c21bd03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7517, 0.8892, 0.2351, 0.0933],\n",
      "        [0.5382, 0.1615, 0.2184, 0.2742],\n",
      "        [0.2024, 0.8814, 0.0906, 0.7065]])\n",
      "tensor([[0.5749, 0.4414, 0.7201, 0.9755],\n",
      "        [0.3712, 0.4646, 0.7341, 0.4726],\n",
      "        [0.5614, 0.6795, 0.0382, 0.0940]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4) \n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "72130c08-5ff8-4ea2-96eb-74b700c083a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's mae some random but reproducible tensors\n",
    "# Set random seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962d4e5-7175-4ee6-9edb-c35309c74f97",
   "metadata": {},
   "source": [
    "Extra resources for reproducibility:\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c793ea-0874-422b-9b9b-68fe2ac3672e",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working good together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07793f9d-5bde-45a4-a3f7-63c52dda58ae",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options... see this post for what option to get: https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/\n",
    "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and acces them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "cc3286d5-0f89-4c8c-be69-bb234d2c7143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 31 17:54:54 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:01:00.0 Off |                  Off |\n",
      "| 67%   85C    P2   295W / 300W |  45185MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "|  0%   29C    P8     7W / 270W |      8MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd485e-22f2-4dcf-8e41-f4cbf0308cd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "fc6c5c02-5127-4ae0-bfb1-5625b4d4188e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32aa33-d8a4-42ca-9490-60363235b550",
   "metadata": {},
   "source": [
    "PyTorch can run on GPU or CPU, set up device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "094335f4-ac07-49e4-aaa5-5e6a7cb0bb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "199ad8b6-92d4-4ced-aebd-6c28d7e1458a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count numbers of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a64416-6316-484b-8a65-2e18a9562d63",
   "metadata": {},
   "source": [
    "## 3. Putting tensors and models on the GPU\n",
    "\n",
    "The reason we want our tensors/models in the GPU is beacuse using a GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "953f58bf-422c-4435-9b28-da9434226263",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default is on the CPU)\n",
    "tensor = torch.tensor([1, 2, 3], device='cpu')\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "43c83951-e20e-4209-9ab3-4fe546d1147d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c778c9-d8b3-4f00-b262-7816b8d7b6db",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ef4ad11e-d19d-42e0-8cb2-c2c4e99195ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[311], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5b51b3bf-c1fe-4327-a1ff-d14c9889c1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b6fa70d2-affa-4fac-bdb8-b05b860dfffa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fec49c-9f9b-4f56-b023-739871ff636a",
   "metadata": {},
   "source": [
    "## Exercises and Extra-cirruculum\n",
    "\n",
    "https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "34ec4d7e-9c71-464b-98a8-cbcd0e5b0e18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5932, 0.1123, 0.1535, 0.2417, 0.7262, 0.7011, 0.2038],\n",
       "        [0.6511, 0.7745, 0.4369, 0.5191, 0.6159, 0.8102, 0.9801],\n",
       "        [0.1147, 0.3168, 0.6965, 0.9143, 0.9351, 0.9412, 0.5995],\n",
       "        [0.0652, 0.5460, 0.1872, 0.0340, 0.9442, 0.8802, 0.0012],\n",
       "        [0.5936, 0.4158, 0.4177, 0.2711, 0.6923, 0.2038, 0.6833],\n",
       "        [0.7529, 0.8579, 0.6870, 0.0051, 0.1757, 0.7497, 0.6047],\n",
       "        [0.1100, 0.2121, 0.9704, 0.8369, 0.2820, 0.3742, 0.0237]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(7, 7)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "861acba6-c656-464f-899d-06b2de639cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2239],\n",
       "        [2.0847],\n",
       "        [1.9002],\n",
       "        [0.9408],\n",
       "        [1.5213],\n",
       "        [1.3606],\n",
       "        [0.8780]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(random_tensor, torch.rand(1, 7).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d0df6059-7bcd-45b9-8c70-e4d7f74f8ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8542],\n",
       "        [1.9611],\n",
       "        [2.2884],\n",
       "        [3.0481],\n",
       "        [1.7067],\n",
       "        [2.5290],\n",
       "        [1.7989]])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "                  \n",
    "random_tensor = torch.rand(7, 7)\n",
    "torch.matmul(random_tensor, torch.rand(1, 7).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "14fe60f2-028b-48f4-9627-1268daaa7bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7541ec83-0ea1-4f3c-8b02-800c328ff49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "a = torch.rand(2, 3).to(device)\n",
    "b = torch.rand(2, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8fc1f215-8048-40cb-b5f7-5f28b1020dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3647, 0.4709],\n",
       "        [0.5184, 0.5617]], device='cuda:0')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a @ b.T\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0001fbed-824d-4b9a-8f03-2798b8de76d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5617, device='cuda:0'), tensor(0.3647, device='cuda:0'))"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.max(), c.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "700bb34f-8635-48ad-9081-41b4df68d1bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.argmax(), c.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "207aaf3b-8cfb-4b56-87cc-8fee41669e24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "\n",
    "d = torch.rand(1, 1, 1, 10)\n",
    "\n",
    "print(d, d.shape)\n",
    "\n",
    "print(d.squeeze(), d.squeeze().shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
